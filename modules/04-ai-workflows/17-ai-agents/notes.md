# Module 17: Deeper AI Agents

## Overview
**LONGEST MODULE (138 minutes)** - Master advanced AI agent architecture including system vs user prompts, few-shot learning, structured outputs, tools, memory, and production patterns.

## Module Information
- **Phase**: Phase 4 - AI Workflows
- **Duration**: 138 minutes (COURSE LONGEST!)
- **Complexity**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Advanced (CRITICAL)
- **Workflows Built**: 5+ AI agent examples
- **Prerequisites**: Module 06 (AI Basics)

## Learning Objectives

- Master system vs user prompts (80/20 rule)
- Implement few-shot learning patterns
- Create structured outputs with parsers
- Attach tools to AI agents
- Manage AI agent memory
- Choose optimal models for cost/performance
- Prevent hallucinations
- Build production-ready AI systems

## Core Concepts

### System Prompt vs User Prompt

**User Prompt**:
- **Changes every time**
- User input or dynamic content
- Example: "Translate: Hello world"
-

 Where user enters their request

**System Prompt**:
- **Static instructions** (rarely changes)
- Defines agent behavior, rules, examples
- **80% of your effort should go here**
- Location: Options ‚Üí System Message

**Key Rule**: 
> A great system message can compensate for poor user prompts

### Few-Shot Learning

**Zero-Shot** (No examples):
```
System: You translate English to Spanish
User: Hello
Result: Hola (works but inconsistent)
```

**One-Shot** (1 example):
```
System: You translate English to Spanish
Example: "Hello" ‚Üí "Hola"
User: Goodbye
Result: Adi√≥s (better)
```

**Few-Shot** (2+ examples) - **BEST**:
```
System: You translate English to Spanish
Examples:
  "Hello" ‚Üí "Hola"
  "Welcome" ‚Üí "Bienvenido"
  "Thanks" ‚Üí "Gracias"
User: Goodbye
Result: Adi√≥s (most reliable)
```

**Rule**: More examples = better results

## Structured Output Parsing

### Why Structure Output?

**Problem**: AI returns freeform text
- "The translation is: Hola! Hope this helps!"
- Hard to extract for next workflow step

**Solution**: Force specific JSON format

**Output Parsers**:
1. **Structured Output Parser** (Most common)
2. JSON Schema Parser

### Structured Output Example

**Setup**:
```
AI Agent
  ‚Üí Options ‚Üí Require Specific Output Format
  ‚Üí Add Structured Output Parser

Parser Configuration:
{
  "language": "Spanish",
  "message_to_translate": "Hello",
  "translated_message": "Hola"
}
```

**Result**: Clean, predictable JSON every time

**Benefits**:
- Extract specific fields easily
- No extra "helpful" text
- Ready for next workflow node
- Consistent format

## Model Selection Strategy

### Knowledge Cutoff Dates

**Critical**: Models trained on OLD data!

**Examples** (as of course time):
-

 Claude Opus 4.5: May 2025
- Claude Sonnet 4.5: January 2025
- GPT-5 Models: Varies

**Problem**: Can't answer recent questions
**Solution**: Use tools (Perplexity, Tavily, OpenAI Responses API)

### Model Tiers

**Claude Models**:
- **Opus**: Most intelligent, expensive ($5-25/M tokens)
- **Sonnet**: Balanced ($3-15/M tokens)  
- **Haiku**: Fastest, cheapest ($1-5/M tokens)

**OpenAI Models**:
- **GPT-5o**: Best for coding ($1.75-14/M tokens)
- **GPT-5o Mini**: Cheap for demos ($0.25-2/M tokens)

**Pricing Breakdown**:
- **Input tokens**: Your prompt cost
- **Output tokens**: Response cost (more expensive)
- **Context window**: How much text can fit

### Cost Optimization Tips

**Test Cheaper Models First**:
```
1. Start with Mini/Haiku
2. Test if results acceptable
3. If not, upgrade to Sonnet/GPT-5o
4. Use expensive models only when needed
```

**Why**: Sometimes cheap models work perfectly!

## Fallback Models

### Production Reliability

**Problem**: What if OpenAI is down?

**Solution**: Add backup models

**Setup**:
```
AI Agent Node
  ‚Üí Chat Model: OpenAI GPT-5o
  ‚Üí Add Fallback Model: Claude Sonnet 4.5
  ‚Üí Add Fallback Model: Google Gemini
```

**Pattern**: Primary ‚Üí Backup 1 ‚Üí Backup 2

**Critical**: Always have fallback in production

## AI Agent Configuration Options

### Complete Setup

**AI Agent can connect**:
1. **Chat Model** (required) - Primary LLM
2. **Fallback Models** (0-4) - Backup LLMs
3. **Memory** (optional) - Conversation history
4. **Tools** (0-many) - External capabilities
5. **Output Parser** (optional) - Structured results

### Memory

**When to Use**: Chat conversations

**Pattern**:
```
Chat Trigger
  ‚Üì
AI Agent + Memory (Window Buffer)
  ‚Üí Remembers last N messages
  ‚Üí Contextual responses
```

**Without Memory**: Each message independent
**With Memory**: Full conversation context

## Tools for AI Agents

### What Are Tools?

**Definition**: Give AI access to external services

**Common Tools**:
- Gmail (send emails)
- Google Sheets (read/write data)
- Google Calendar (schedule)
- HTTP Request (call APIs)
- Code Executor (run JavaScript)
- Calculator (math operations)

### Tool Pattern

```
User: "Email the Q4 report to the team"
  ‚Üì
AI Agent + Gmail Tool
  ‚Üí AI understands intent
  ‚Üí Calls Gmail tool automatically
  ‚Üí Sends email
  ‚Üí Confirms to user
```

**Without Tools**: AI can only generate text
**With Tools**: AI can take actions

## Prompt Engineering Best Practices

### System Message Checklist

**1. Role & Identity**:
```
You are an AI agent that translates English to Spanish.
```

**2. Tools Available**:
```
You have access to Gmail for sending emails.
```

**3. Error Handling**:
```
If translation fails, respond: "I cannot translate this."
If Gmail fails, notify user and log error.
```

**4. Tone**:
```
Be professional and concise.
```

**5. Rules & Restrictions**:
```
- Never translate profanity
- Maximum 500 words per translation
- Only translate between English and Spanish
```

**6. Examples** (Few-shot):
```
Message: "Hello"  
Translation: "Hola"

Message: "Goodbye"  
Translation: "Adi√≥s"
```

**7. Output Format**:
```
Always respond in this JSON format:
{
  "original": "text",
  "translated": "text",
  "language": "Spanish"
}
```

### One Task Per Agent

**Bad** (Too many tasks):
```
System: Extract data, summarize it, create social post, send email
```
Problems: Confusing, error-prone, low quality

**Good** (Chain agents):
```
Agent 1: Extract data
  ‚Üì
Agent 2: Summarize
  ‚Üì
Agent 3: Create social post
  ‚Üì
Agent 4: Send email
```
Benefits: Clear, accurate, debuggable

## Context Window Management

### The Problem

**Claim**: "1 million token context window!"
**Reality**: Performance degrades with too much context

**Research**: "Lost in the Middle" problem
- AI forgets information in long contexts
- Middle content ignored
- Quality decreases

**Best Practice**: Keep prompts focused and concise

**Don't**: Dump entire documents
**Do**: Extract relevant sections first

## Preventing Hallucinations

### What Are Hallucinations?

**Definition**: AI confidently states incorrect information

**Example**:
- User: "Who won Super Bowl 2026?"
- AI (trained on 2025 data): "The [random team]!" (WRONG - made it up)

### Prevention Strategies

**1. System Prompt Instructions**:
```
If you don't know the answer, say "I don't know" 
instead of guessing.
```

**2. Use Current Data Tools**:
- Perplexity (real-time search)
- Tavily (search API)
- OpenAI Responses API
- Web scraping tools

**3. Validate Outputs**:
- Cross-check critical facts
- Ask for sources
- Implement verification steps

**4. Great System Messages**:
- Clear instructions
- Good examples
- Explicit rules

## Practical Workflows

### Workflow 1: Translation Agent with Dynamic Language

```
Manual Trigger
  ‚Üì
Edit Fields:
  - translation_string: "Free N8N templates"
  - language: "Hindi" (user choice)
  ‚Üì
AI Agent:
  System: You translate English to [language]
  User: {{$json.translation_string}}
  Output Parser: Structured JSON
  ‚Üì
Result: Clean translated output
```

### Workflow 2: Multi-Agent Pipeline

```
Data Source
  ‚Üì
Agent 1: Extract key information
  ‚Üì
Agent 2: Summarize findings
  ‚Üì
Agent 3: Generate social media post
  ‚Üì
Gmail: Send to team
```

### Workflow 3: AI with Tools

```
Chat Trigger: "Schedule meeting with John tomorrow at 2pm"
  ‚Üì
AI Agent + Google Calendar Tool
  ‚Üí Understands intent
  ‚Üí Calls calendar tool
  ‚Üí Creates event
  ‚Üí Confirms to user
```

## Key Takeaways

- üéØ **80% effort on system prompt**, 20% on user prompt
- üéØ **Few-shot learning** (examples) = better results
- üéØ **Structured outputs** for workflow consistency
- üéØ **One task per agent** = higher quality
- üéØ **Fallback models** = production reliability
- üí° Test cheap models first (Mini/Haiku)
- üí° Keep context concise (avoid "lost in middle")
- ‚ö†Ô∏è Models have knowledge cutoffs - use tools for current data
- ‚ö†Ô∏è Hallucinations happen - prompt to say "I don't know"

## Common Mistakes

| Mistake | Problem | Solution |
|---------|---------|----------|
| Generic system prompt | Poor results | Detailed instructions + examples |
| No structured output | Inconsistent data | Use Output Parser |
| Too many tasks | Quality suffers | One agent per task |
| No fallback model | Downtime failures | Add backup models |
| Ignoring knowledge cutoff | Wrong answers | Add real-time tools |
| Trusting all outputs | Hallucinations | Validate critical information |

## Tools Covered

- Chat Model nodes (OpenAI, Claude, Gemini)
- Window Buffer Memory
- Structured Output Parser
- Gmail Tool
- Google Sheets Tool
- HTTP Request Tool
- Calculator Tool

## Related Modules

**Prerequisites**:
- [Module 06: AI Basics](../../02-fundamentals/06-ai-basics/notes.md) - Getting started

**Builds to**:
- [Module 20: Advanced AI Nodes](../20-advanced-ai-nodes/notes.md) - Specialized configurations
- [Module 22: RAG Basics](../22-rag-basics/notes.md) - Knowledge-based AI

**Uses With**:
- [Module 14: API Workflows](../../03-integrations/14-api-workflows/notes.md) - AI + APIs
- [Module 19: Error Handling](../19-error-handling/notes.md) - Production reliability

## Additional Resources

- [Anthropic Pricing](https://www.anthropic.com/pricing)
- [OpenAI Pricing](https://openai.com/api/pricing/)
- [Few-Shot Learning Guide](https://www.promptingguide.ai/techniques/fewshot)
- [Lost in the Middle Research](https://arxiv.org/abs/2307.03172)

---

**Module Status**: ‚úÖ Completed  
**Date Completed**: 2026-01-15  
**Time Spent**: 138 minutes (LONGEST MODULE)  
**Complexity**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Advanced  
**Impact**: CRITICAL for AI mastery  
**Next Module**: [Module 18: ChatHub](../18-chathub/notes.md)
